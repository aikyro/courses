{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0204311",
   "metadata": {},
   "source": [
    "# Part 1: From Chatbot to Agent — The Key Difference\n",
    "**Duration:** ~20 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what a simple chatbot does (just Q&A)\n",
    "- See how adding **tools** transforms a chatbot into an **agent**\n",
    "- Observe how the LLM decides when to use a tool vs answer directly\n",
    "- Visualize the complete agent flow\n",
    "\n",
    "## Prerequisites\n",
    "- Google API key (get one at https://aistudio.google.com/apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46751f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing dependencies...\\n\")\n",
    "%pip install --quiet google-genai\n",
    "print(\"\\nAll dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07e7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google API key:  AIzaSyCKnXCtBcOfELgQmtD6pO5JOKXftqFODJI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key = input(\"Paste your Google API key: \").strip()\n",
    "if api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "    print(\"API key configured successfully\")\n",
    "else:\n",
    "    print(\"ERROR: API key is required for this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd056bcc",
   "metadata": {},
   "source": [
    "## Demo 1: A Simple Q&A Chatbot\n",
    "\n",
    "A **chatbot** just answers questions from its training data. It has:\n",
    "- No access to real-time information\n",
    "- No ability to perform calculations\n",
    "- No way to interact with external systems\n",
    "\n",
    "Let's build one and see its limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb92c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLE CHATBOT — Knowledge Questions\n",
      "============================================================\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: The capital of France is **Paris**.\n",
      "\n",
      "\n",
      "Q: Explain photosynthesis in one sentence.\n",
      "A: Photosynthesis is the process by which plants and other organisms use sunlight to convert carbon dioxide and water into glucose for energy, releasing oxygen as a byproduct.\n",
      "\n",
      "\n",
      "Q: Who wrote Romeo and Juliet?\n",
      "A: William Shakespeare wrote Romeo and Juliet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "def simple_chatbot(question: str) -> str:\n",
    "    \"\"\"A simple chatbot that just answers questions - no tools.\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=question\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "# Test with knowledge questions\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain photosynthesis in one sentence.\",\n",
    "    \"Who wrote Romeo and Juliet?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMPLE CHATBOT — Knowledge Questions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    answer = simple_chatbot(q)\n",
    "    print(f\"A: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a732345",
   "metadata": {},
   "source": [
    "## The Limitation: What a Chatbot Can't Do\n",
    "\n",
    "Now let's ask questions that require **real-time data** or **computation**.\n",
    "The chatbot can only guess — it has no way to actually check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41a6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLE CHATBOT — Questions Requiring Real-World Access\n",
      "============================================================\n",
      "\n",
      "Q: What is the exact current time right now?\n",
      "A: Unfortunately, I cannot give you the exact current time. As an AI, I do not have real-time access to the system clock or external time servers. \n",
      "\n",
      "To find the exact current time, please check the clock on your computer, phone, or watch, or search \"current time\" on Google.\n",
      "\n",
      "\n",
      "Q: What is 847 * 293 + 156 / 12?\n",
      "A: To solve this problem, we need to follow the order of operations, which is often remembered by the acronym PEMDAS (Parentheses, Exponents, Multiplication and Division (from left to right), Addition and Subtraction (from left to right)).\n",
      "First, we perform the multiplication and division:\n",
      "847 * 293 = 248171\n",
      "156 / 12 = 13\n",
      "Now, we perform the addition:\n",
      "248171 + 13 = 248184\n",
      "So, the answer is 248184.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{248184}$\n",
      "\n",
      "Q: What is today's date?\n",
      "A: Today is October 27, 2023.\n",
      "\n",
      "\n",
      "============================================================\n",
      "NOTICE: The chatbot tries to answer but it's GUESSING.\n",
      "It cannot actually check the time, compute math reliably,\n",
      "or access real-time data.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "hard_questions = [\n",
    "    \"What is the exact current time right now?\",\n",
    "    \"What is 847 * 293 + 156 / 12?\",\n",
    "    \"What is today's date?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMPLE CHATBOT — Questions Requiring Real-World Access\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in hard_questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    answer = simple_chatbot(q)\n",
    "    print(f\"A: {answer}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NOTICE: The chatbot tries to answer but it's GUESSING.\")\n",
    "print(\"It cannot actually check the time, compute math reliably,\")\n",
    "print(\"or access real-time data.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0e634",
   "metadata": {},
   "source": [
    "## Demo 2: Adding Tools — Turning a Chatbot into an Agent\n",
    "\n",
    "An **agent** = LLM + **Tools** + **Decision Making**\n",
    "\n",
    "The key difference: the LLM can now **decide** to call a tool when it needs\n",
    "real-world data or computation, instead of guessing.\n",
    "\n",
    "Let's add two tools:\n",
    "1. `get_current_time()` — returns the actual current date and time\n",
    "2. `calculator(expression)` — evaluates math expressions accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524276d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_current_time()\n",
      "  Result: {'current_time': '2026-02-12 19:59:08', 'timezone': 'local'}\n",
      "\n",
      "Tool: calculator('847 * 293 + 156 / 12')\n",
      "  Result: {'expression': '847 * 293 + 156 / 12', 'result': '248184.0'}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_current_time() -> dict:\n",
    "    \"\"\"Returns the current date and time.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return {\n",
    "        \"current_time\": now.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"timezone\": \"local\"\n",
    "    }\n",
    "\n",
    "def calculator(expression: str) -> dict:\n",
    "    \"\"\"Evaluates a mathematical expression and returns the result.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 3 * 4')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return {\"expression\": expression, \"result\": str(result)}\n",
    "    except Exception as e:\n",
    "        return {\"expression\": expression, \"error\": str(e)}\n",
    "\n",
    "# Quick test\n",
    "print(\"Tool: get_current_time()\")\n",
    "print(f\"  Result: {get_current_time()}\")\n",
    "print()\n",
    "print(\"Tool: calculator('847 * 293 + 156 / 12')\")\n",
    "print(f\"  Result: {calculator('847 * 293 + 156 / 12')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6fde94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def agent_with_tools(question: str, require_tool: bool = False) -> str:\n",
    "    \"\"\"An agent that can use tools to answer questions.\n",
    "\n",
    "    This function shows the COMPLETE agent loop:\n",
    "    1. Send question + tool definitions to LLM\n",
    "    2. LLM decides: answer directly OR call a tool\n",
    "    3. If tool call: execute it, send result back to LLM\n",
    "    4. LLM generates final answer using tool result\n",
    "\n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        require_tool: If True, forces the LLM to call a tool (mode='ANY').\n",
    "                      If False, the LLM decides whether to use a tool (mode='AUTO').\n",
    "    \"\"\"\n",
    "\n",
    "    # Available tools\n",
    "    tool_functions = {\n",
    "        \"get_current_time\": get_current_time,\n",
    "        \"calculator\": calculator,\n",
    "    }\n",
    "\n",
    "    mode = \"ANY\" if require_tool else \"AUTO\"\n",
    "    print(f\"  [Step 1] Sending question to LLM with tools (mode={mode})...\")\n",
    "\n",
    "    # tool_config controls whether the LLM MUST call a tool or can decide\n",
    "    # mode='ANY'  -> LLM must call a tool\n",
    "    # mode='AUTO' -> LLM decides whether to use a tool or answer directly\n",
    "    tool_config = types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=mode)\n",
    "    )\n",
    "\n",
    "    # Send to LLM with tools available\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=question,\n",
    "        config=types.GenerateContentConfig(\n",
    "            tools=[get_current_time, calculator],\n",
    "            tool_config=tool_config,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Check if LLM decided to call a tool\n",
    "    candidate = response.candidates[0]\n",
    "\n",
    "    # Look for function calls in the response\n",
    "    function_calls = [\n",
    "        part for part in candidate.content.parts\n",
    "        if part.function_call\n",
    "    ]\n",
    "\n",
    "    if not function_calls:\n",
    "        # LLM answered directly — no tool needed\n",
    "        text_parts = [part.text for part in candidate.content.parts if part.text]\n",
    "        answer = \"\".join(text_parts)\n",
    "        print(f\"  [Step 2] LLM answered DIRECTLY (no tool needed)\")\n",
    "        return answer\n",
    "\n",
    "    # LLM wants to call a tool\n",
    "    fc = function_calls[0]\n",
    "    tool_name = fc.function_call.name\n",
    "    tool_args = dict(fc.function_call.args) if fc.function_call.args else {}\n",
    "\n",
    "    print(f\"  [Step 2] LLM decided to call tool: {tool_name}({tool_args})\")\n",
    "\n",
    "    # Execute the tool\n",
    "    tool_fn = tool_functions[tool_name]\n",
    "    tool_result = tool_fn(**tool_args)\n",
    "    print(f\"  [Step 3] Tool executed. Result: {tool_result}\")\n",
    "\n",
    "    # Send the tool result back to the LLM\n",
    "    print(f\"  [Step 4] Sending tool result back to LLM for final answer...\")\n",
    "\n",
    "    follow_up = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[\n",
    "            types.Content(role=\"user\", parts=[types.Part(text=question)]),\n",
    "            candidate.content,\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(\n",
    "                    function_response=types.FunctionResponse(\n",
    "                        name=tool_name,\n",
    "                        response=tool_result\n",
    "                    )\n",
    "                )]\n",
    "            ),\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            tools=[get_current_time, calculator],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_text = follow_up.text\n",
    "    print(f\"  [Step 5] LLM generated final answer using tool result\")\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e68afad",
   "metadata": {},
   "source": [
    "## Seeing the Agent in Action\n",
    "\n",
    "Now let's ask the **same questions** we asked the simple chatbot.\n",
    "Watch the agent's decision-making process in the trace output.\n",
    "\n",
    "We use `require_tool=True` to guarantee the LLM calls a tool (mode `ANY`).\n",
    "This makes the demo reliable — in production, you'd use `AUTO` mode so the\n",
    "LLM decides on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a76058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGENT — Questions Requiring Tools (require_tool=True)\n",
      "============================================================\n",
      "\n",
      "Q: What is the exact current time right now?\n",
      "----------------------------------------\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: get_current_time({})\n",
      "  [Step 3] Tool executed. Result: {'current_time': '2026-02-12 20:00:01', 'timezone': 'local'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "\n",
      "Final Answer: The current time is 2026-02-12 20:00:01 local time.\n",
      "\n",
      "Q: What is 847 * 293 + 156 / 12?\n",
      "----------------------------------------\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: calculator({'expression': '847 * 293 + 156 / 12'})\n",
      "  [Step 3] Tool executed. Result: {'expression': '847 * 293 + 156 / 12', 'result': '248184.0'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "\n",
      "Final Answer: The answer is 248184.0.\n",
      "\n",
      "Q: What is the square root of 144?\n",
      "----------------------------------------\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: calculator({'expression': '144**0.5'})\n",
      "  [Step 3] Tool executed. Result: {'expression': '144**0.5', 'result': '12.0'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "\n",
      "Final Answer: The square root of 144 is 12.\n"
     ]
    }
   ],
   "source": [
    "tool_questions = [\n",
    "    \"What is the exact current time right now?\",\n",
    "    \"What is 847 * 293 + 156 / 12?\",\n",
    "    \"What is the square root of 144?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENT — Questions Requiring Tools (require_tool=True)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in tool_questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(\"-\" * 40)\n",
    "    answer = agent_with_tools(q, require_tool=True)\n",
    "    print(f\"\\nFinal Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed90022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGENT — Knowledge Questions (require_tool=False)\n",
      "============================================================\n",
      "For these questions, no tool is needed.\n",
      "The agent answers directly from its training data.\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: The capital of France is **Paris**.\n",
      "\n",
      "Q: Explain photosynthesis in one sentence.\n",
      "A: Photosynthesis is the process by which plants and other organisms use sunlight to synthesize foods with the help of water and carbon dioxide, releasing oxygen as a byproduct.\n",
      "\n",
      "Q: Who wrote Romeo and Juliet?\n",
      "A: William Shakespeare wrote Romeo and Juliet.\n",
      "\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHT: The agent uses tools ONLY when needed.\n",
      "  - Time/math questions   -> calls a tool (require_tool=True)\n",
      "  - Knowledge questions   -> answers directly (no tool)\n",
      "\n",
      "In production, tool_config mode='AUTO' lets the LLM decide.\n",
      "mode='ANY' forces a tool call (useful for guaranteed demos).\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "knowledge_questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain photosynthesis in one sentence.\",\n",
    "    \"Who wrote Romeo and Juliet?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENT — Knowledge Questions (require_tool=False)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"For these questions, no tool is needed.\")\n",
    "print(\"The agent answers directly from its training data.\\n\")\n",
    "\n",
    "for q in knowledge_questions:\n",
    "    print(f\"Q: {q}\")\n",
    "    # No tool needed — answer directly like a chatbot\n",
    "    answer = simple_chatbot(q)\n",
    "    print(f\"A: {answer}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT: The agent uses tools ONLY when needed.\")\n",
    "print(\"  - Time/math questions   -> calls a tool (require_tool=True)\")\n",
    "print(\"  - Knowledge questions   -> answers directly (no tool)\")\n",
    "print(\"\")\n",
    "print(\"In production, tool_config mode='AUTO' lets the LLM decide.\")\n",
    "print(\"mode='ANY' forces a tool call (useful for guaranteed demos).\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3104e",
   "metadata": {},
   "source": [
    "## The Agent Flow — Visualized\n",
    "\n",
    "```\n",
    "User Question\n",
    "     |\n",
    "     v\n",
    "+---------+\n",
    "|   LLM   | <-- Has tool definitions\n",
    "+----+----+\n",
    "     |\n",
    "     v\n",
    " Decision:\n",
    " Can I answer    YES --> Direct Answer --> Response to User\n",
    " from my          \n",
    " knowledge?      \n",
    "     | NO\n",
    "     v\n",
    " Select Tool\n",
    "     |\n",
    "     v\n",
    "+----------+\n",
    "| Execute  |  (get_current_time, calculator, etc.)\n",
    "|   Tool   |\n",
    "+----+-----+\n",
    "     |\n",
    "     v\n",
    " Tool Result\n",
    "     |\n",
    "     v\n",
    "+---------+\n",
    "|   LLM   | <-- Incorporates tool result\n",
    "+----+----+\n",
    "     |\n",
    "     v\n",
    " Final Response --> User\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Feature | Chatbot | Agent |\n",
    "|---------|---------|-------|\n",
    "| Knowledge Q&A | Yes | Yes |\n",
    "| Real-time data | No (guesses) | Yes (uses tools) |\n",
    "| Computation | No (unreliable) | Yes (uses tools) |\n",
    "| Decision making | None | Chooses when to use tools |\n",
    "| External access | None | Via tool functions |\n",
    "\n",
    "**In the next part**, we'll build a full research assistant with multiple tools using Google ADK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a7bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIDE-BY-SIDE: Chatbot vs Agent\n",
      "============================================================\n",
      "\n",
      "Question: What is 2847 * 391?\n",
      "--------------------------------------------------\n",
      "[Chatbot]:\n",
      "  To calculate 2847 * 391, we can use the standard multiplication method:\n",
      "\n",
      "     2847\n",
      "   x  391\n",
      "   ------\n",
      "     2847  (2847 * 1)\n",
      "  256230  (2847 * 90)\n",
      "+ 854100  (2847 * 300)\n",
      "   ------\n",
      " 1113177\n",
      "\n",
      "So, 2847 *\n",
      "[Agent]:\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: calculator({'expression': '2847 * 391'})\n",
      "  [Step 3] Tool executed. Result: {'expression': '2847 * 391', 'result': '1113177'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "  2847 * 391 = 1113177\n",
      "\n",
      "Question: What year did World War II end?\n",
      "--------------------------------------------------\n",
      "[Chatbot]:\n",
      "  World War II ended in **1945**.\n",
      "[Agent]:\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: get_current_time({})\n",
      "  [Step 3] Tool executed. Result: {'current_time': '2026-02-12 20:06:11', 'timezone': 'local'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "  I don't have information about historical events like the end of World War II. My capabilities are limited to providing the current time and evaluating mathematical expressions.\n",
      "\n",
      "Question: What time is it right now?\n",
      "--------------------------------------------------\n",
      "[Chatbot]:\n",
      "  I do not have access to real-time information, including the current time. To find out the current time, please check your phone, computer, or other time-telling device.\n",
      "[Agent]:\n",
      "  [Step 1] Sending question to LLM with tools (mode=ANY)...\n",
      "  [Step 2] LLM decided to call tool: get_current_time({})\n",
      "  [Step 3] Tool executed. Result: {'current_time': '2026-02-12 20:06:33', 'timezone': 'local'}\n",
      "  [Step 4] Sending tool result back to LLM for final answer...\n",
      "  [Step 5] LLM generated final answer using tool result\n",
      "  It is 20:06:33.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SIDE-BY-SIDE: Chatbot vs Agent\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_questions = [\n",
    "    \"What is 2847 * 391?\",\n",
    "    \"What year did World War II end?\",\n",
    "    \"What time is it right now?\",\n",
    "]\n",
    "\n",
    "for q in comparison_questions:\n",
    "    print(f\"\\nQuestion: {q}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    print(\"[Chatbot]:\")\n",
    "    chatbot_answer = simple_chatbot(q)\n",
    "    print(f\"  {chatbot_answer.strip()[:200]}\")\n",
    "\n",
    "    print(\"[Agent]:\")\n",
    "    agent_answer = agent_with_tools(q, require_tool=True)\n",
    "    print(f\"  {agent_answer.strip()[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58922f5c-f66a-4191-8a02-b63adddbfc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
