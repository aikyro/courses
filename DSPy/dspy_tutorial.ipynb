{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02af7f74",
   "metadata": {},
   "source": [
    "# DSPy Tutorial: Understanding Prompt Engineering Enhancement\n",
    "\n",
    "This notebook demonstrates how **DSPy** (Declarative Self-improving Python) enhances and optimizes prompts for LLMs. We'll explore:\n",
    "\n",
    "1. **Zero-shot prompting** - Direct predictions without examples\n",
    "2. **Few-shot prompting** - Learning from examples\n",
    "3. **Chain of Thought** - Step-by-step reasoning\n",
    "4. **Custom Signatures** - Structured input/output definitions\n",
    "\n",
    "## What is DSPy?\n",
    "\n",
    "DSPy is a framework that treats prompts as code, making them:\n",
    "- **Composable**: Build complex pipelines from simple components\n",
    "- **Optimizable**: Automatically improve prompts using validation\n",
    "- **Maintainable**: Separate logic from prompt engineering\n",
    "- **Type-safe**: Use Python types and signatures\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831dd70",
   "metadata": {},
   "source": [
    "***IMPORTANT INSTALLATIONS BEFORE EXECUTION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5bfafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: dspy-ai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.27)\n",
      "Collecting dspy-ai\n",
      "  Using cached dspy_ai-3.0.4-py3-none-any.whl.metadata (285 bytes)\n",
      "Requirement already satisfied: litellm>=1.63.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.63.7)\n",
      "Collecting litellm>=1.63.2\n",
      "  Using cached litellm-1.80.10-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: openai<1.62.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.61.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<1.62.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai<1.62.0) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai<1.62.0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai<1.62.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<1.62.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<1.62.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<1.62.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<1.62.0) (0.4.2)\n",
      "Collecting dspy>=3.0.4 (from dspy-ai)\n",
      "  Using cached dspy-3.0.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiohttp>=3.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (3.13.2)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (0.14.0)\n",
      "Collecting grpcio<1.68.0,>=1.62.3 (from litellm>=1.63.2)\n",
      "  Using cached grpcio-1.67.1-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (4.25.1)\n",
      "INFO: pip is looking at multiple versions of litellm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting litellm>=1.63.2\n",
      "  Using cached litellm-1.80.9-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.80.8-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.80.7-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.80.6-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.80.5-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.80.0-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.79.3-py3-none-any.whl.metadata (30 kB)\n",
      "INFO: pip is still looking at multiple versions of litellm to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached litellm-1.79.2-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.79.1-py3-none-any.whl.metadata (30 kB)\n",
      "  Using cached litellm-1.79.0-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.7-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.6-py3-none-any.whl.metadata (42 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached litellm-1.78.5-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.4-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.3-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.2-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.78.0-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.77.7-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.77.5-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.77.4-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.77.3-py3-none-any.whl.metadata (42 kB)\n",
      "  Using cached litellm-1.77.2.post1.tar.gz (10.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.77.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.77.0-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.76.3-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.76.2-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.76.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.76.0-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.9-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.8-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.7-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.6-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.5.post2-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.5.post1-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached litellm-1.75.4-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.75.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.75.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.75.0-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.15.post2.tar.gz (9.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.15.post1.tar.gz (9.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.15-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.14-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.12-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.9.post2-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.9.post1-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.9-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.8-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.7.post2.tar.gz (9.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.7.post1.tar.gz (9.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.7-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.6-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.4-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.3.post1.tar.gz (9.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.1-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.74.0.post2.tar.gz (9.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.0.post1.tar.gz (9.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.74.0-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.73.7-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached litellm-1.73.6.post1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.73.6-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.73.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.73.1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.73.0.post1.tar.gz (8.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.73.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.9-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.7-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.6.post2.tar.gz (8.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.72.6.post1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.6-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.4-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.2.post1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.72.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.71.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.71.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached litellm-1.71.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting httpx-aiohttp>=0.1.4 (from litellm>=1.63.2)\n",
      "  Using cached httpx_aiohttp-0.1.12-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting litellm>=1.63.2\n",
      "  Using cached litellm-1.71.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached litellm-1.70.4-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached litellm-1.70.2-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached litellm-1.70.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached litellm-1.69.3-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached litellm-1.69.2-py3-none-any.whl.metadata (37 kB)\n",
      "  Using cached litellm-1.69.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.69.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.68.2-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.68.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.68.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.6-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.5-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.4.post1.tar.gz (7.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.67.4-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.2-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.0.post1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.67.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.66.3-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.66.2-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.66.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.66.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.8-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.7-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.6-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.5-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.4.post1.tar.gz (6.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.65.4-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.3-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.65.0.post1.tar.gz (6.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached litellm-1.65.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.64.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.14-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.12-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.11-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.8-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from litellm>=1.63.2) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.63.2) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.63.2) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.63.2) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.63.2) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.63.2) (0.30.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: backoff>=2.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
      "Requirement already satisfied: regex>=2023.10.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (2025.11.3)\n",
      "Requirement already satisfied: orjson>=3.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (3.11.5)\n",
      "Requirement already satisfied: optuna>=3.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (4.6.0)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (0.1.6)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (0.54.3)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (9.1.2)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (6.2.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
      "Requirement already satisfied: rich>=13.7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (14.2.0)\n",
      "Requirement already satisfied: pillow>=10.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (12.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (2.3.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
      "Requirement already satisfied: gepa==0.0.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai) (0.0.17)\n",
      "  Using cached litellm-1.63.7-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.6-py3-none-any.whl.metadata (36 kB)\n",
      "  Using cached litellm-1.63.5-py3-none-any.whl.metadata (37 kB)\n",
      "  Using cached litellm-1.63.3-py3-none-any.whl.metadata (37 kB)\n",
      "  Using cached litellm-1.63.2-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting openai<1.62.0\n",
      "  Using cached openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting dspy-ai\n",
      "  Using cached dspy_ai-3.0.3-py3-none-any.whl.metadata (285 bytes)\n",
      "Collecting dspy>=3.0.3 (from dspy-ai)\n",
      "  Using cached dspy-3.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting gepa==0.0.7 (from gepa[dspy]==0.0.7->dspy>=3.0.3->dspy-ai)\n",
      "  Using cached gepa-0.0.7-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting dspy-ai\n",
      "  Using cached dspy_ai-3.0.2-py3-none-any.whl.metadata (285 bytes)\n",
      "Collecting dspy>=3.0.2 (from dspy-ai)\n",
      "  Using cached dspy-3.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: ujson>=5.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=3.0.2->dspy-ai) (5.11.0)\n",
      "Collecting gepa==0.0.4 (from gepa[dspy]==0.0.4->dspy>=3.0.2->dspy-ai)\n",
      "  Using cached gepa-0.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dspy-ai\n",
      "  Using cached dspy_ai-3.0.1-py3-none-any.whl.metadata (285 bytes)\n",
      "Collecting dspy>=3.0.1 (from dspy-ai)\n",
      "  Using cached dspy-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting dspy-ai\n",
      "  Using cached dspy_ai-3.0.0-py3-none-any.whl.metadata (285 bytes)\n",
      "Collecting dspy>=3.0.0 (from dspy-ai)\n",
      "  Using cached dspy-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gepa==0.0.2 (from dspy>=3.0.0->dspy-ai)\n",
      "  Using cached gepa-0.0.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dspy>=2.6.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy-ai) (2.6.27)\n",
      "Requirement already satisfied: pandas>=2.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=2.6.5->dspy-ai) (2.3.3)\n",
      "Requirement already satisfied: datasets>=2.14.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dspy>=2.6.5->dspy-ai) (4.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.4.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (1.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->dspy>=2.6.5->dspy-ai) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp>=3.10->litellm>=1.63.2) (1.22.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm>=1.63.2) (3.23.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.45)\n",
      "Requirement already satisfied: Mako in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy>=2.6.5->dspy-ai) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<1.62.0) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Setup: This cell ensures all necessary libraries are installed for the user\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U google-generativeai\n",
    "!{sys.executable} -m pip install -U dspy-ai \"litellm>=1.63.2\" \"openai<1.62.0\" requests python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9e051",
   "metadata": {},
   "source": [
    "### Configure DSPy with Language Model\n",
    "\n",
    "We'll use Google's Gemini model. Replace the API key with your own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c91706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy configured successfully!\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load keys from .env file\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# Configure DSPy with a language model\n",
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=GOOGLE_API_KEY)\n",
    "dspy.configure(lm=lm)\n",
    "print(\"DSPy configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cdbdf",
   "metadata": {},
   "source": [
    "## 2. Basic Language Model Usage\n",
    "\n",
    "Before diving into DSPy's enhancements, let's see basic LM usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dec867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: ['This is a test!']\n",
      "Result 2: ['Hi there! Test received. How can I help you today? ðŸ˜Š']\n"
     ]
    }
   ],
   "source": [
    "# Basic LM call with a simple string\n",
    "result1 = lm(\"Say this is a test!\", temperature=0.0)\n",
    "print(\"Result 1:\", result1)\n",
    "\n",
    "# Basic LM call with messages format\n",
    "result2 = lm(messages=[{\"role\": \"user\", \"content\": \"hii this is a test!\"}])\n",
    "print(\"Result 2:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f848db",
   "metadata": {},
   "source": [
    "## 3. Zero-Shot Prompting with `dspy.Predict`\n",
    "\n",
    "**Zero-shot** means making predictions without providing examples. DSPy's `Predict` module structures your inputs and outputs.\n",
    "\n",
    "### Simple Zero-Shot Example: Question Answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccebb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "Answer: Paris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 8 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='choices', input_value=Message(content='[[ ## an...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# Define a simple signature using a string format\n",
    "# Format: \"input_field -> output_field: type\"\n",
    "\n",
    "qa = dspy.Predict(\"question -> answer\")\n",
    "result = qa(question=\"What is the capital of France?\")\n",
    "print(f\"Question: What is the capital of France?\")\n",
    "print(f\"Answer: {result.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76284338",
   "metadata": {},
   "source": [
    "### Zero-Shot with Custom Signature Class\n",
    "\n",
    "For more complex scenarios, define a Signature class with type hints and documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91fecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely love this new product! It's amazing!\n",
      "Sentiment: positive\n",
      "Confidence: 0.98\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# Define a custom signature for sentiment classification\n",
    "class SentimentAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze the sentiment of a given text and provide a confidence score.\"\"\"\n",
    "    \n",
    "    text: str = dspy.InputField(desc=\"The text to analyze\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = dspy.OutputField(desc=\"The sentiment classification\")\n",
    "    confidence: float = dspy.OutputField(desc=\"Confidence score between 0 and 1\")\n",
    "\n",
    "# Create a Predict module from the signature\n",
    "classify = dspy.Predict(SentimentAnalysis)\n",
    "\n",
    "# Use it for zero-shot prediction\n",
    "result = classify(text=\"I absolutely love this new product! It's amazing!\")\n",
    "print(f\"Text: I absolutely love this new product! It's amazing!\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20804d54",
   "metadata": {},
   "source": [
    "### Zero-Shot: Text Summarization\n",
    "\n",
    "Another example showing how DSPy structures prompt engineering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8141084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables computers to learn \n",
      "and improve from experience without being explicitly programmed. It uses algorithms to \n",
      "analyze large amounts of data, identify patterns, and make predictions or decisions. \n",
      "Applications range from recommendation systems and image recognition to natural language \n",
      "processing and autonomous vehicles.\n",
      "\n",
      "\n",
      "Summary:\n",
      "Machine learning, a branch of artificial intelligence, allows computers to learn and improve autonomously through experience rather than explicit programming. It operates by employing algorithms to analyze extensive data, pinpoint patterns, and consequently make informed predictions or decisions. This technology finds wide application in areas such as recommendation systems, image recognition, and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "class Summarize(dspy.Signature):\n",
    "    \"\"\"Summarize the given text in 2-3 sentences.\"\"\"\n",
    "    \n",
    "    long_text: str = dspy.InputField()\n",
    "    summary: str = dspy.OutputField()\n",
    "\n",
    "summarizer = dspy.Predict(Summarize)\n",
    "\n",
    "long_text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables computers to learn \n",
    "and improve from experience without being explicitly programmed. It uses algorithms to \n",
    "analyze large amounts of data, identify patterns, and make predictions or decisions. \n",
    "Applications range from recommendation systems and image recognition to natural language \n",
    "processing and autonomous vehicles.\n",
    "\"\"\"\n",
    "\n",
    "result = summarizer(long_text=long_text)\n",
    "print(\"Original text:\")\n",
    "print(long_text)\n",
    "print(\"\\nSummary:\")\n",
    "print(result.summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda06a20",
   "metadata": {},
   "source": [
    "## 4. Few-Shot Prompting with `dspy`\n",
    "\n",
    "**Few-shot learning** provides examples to help the model understand the task better.\n",
    "\n",
    "### Creating Training Examples\n",
    "\n",
    "First, let's define some examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d42daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 examples for few-shot learning\n"
     ]
    }
   ],
   "source": [
    "# Define a signature for our task\n",
    "class Translate(dspy.Signature):\n",
    "    \"\"\"Translate English text to French.\"\"\"\n",
    "    \n",
    "    english: str = dspy.InputField()\n",
    "    french: str = dspy.OutputField()\n",
    "\n",
    "# Create training examples\n",
    "examples = [\n",
    "    dspy.Example(english=\"Hello\", french=\"Bonjour\").with_inputs(\"english\"),\n",
    "    dspy.Example(english=\"Good morning\", french=\"Bonjour\").with_inputs(\"english\"),\n",
    "    dspy.Example(english=\"How are you?\", french=\"Comment allez-vous?\").with_inputs(\"english\"),\n",
    "    dspy.Example(english=\"Thank you\", french=\"Merci\").with_inputs(\"english\"),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(examples)} examples for few-shot learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958689f9",
   "metadata": {},
   "source": [
    "### Few-Shot Predictor\n",
    "\n",
    "Now create a FewShot predictor that uses these examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93b59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-Shot Translation ===\n",
      "English: Good evening\n",
      "French: Bonsoir\n",
      "\n",
      "=== Few-Shot Translation (with examples in signature) ===\n",
      "English: Good evening\n",
      "French: Bonsoir\n"
     ]
    }
   ],
   "source": [
    "# In DSPy, few-shot learning can be demonstrated by including examples in the signature description\n",
    "# or by using the teleprompter system for optimization. For this tutorial, we'll show a conceptual approach.\n",
    "\n",
    "# Method 1: Zero-shot (no examples) - baseline\n",
    "zero_shot_translator = dspy.Predict(Translate)\n",
    "\n",
    "# Method 2: Enhanced signature with example pattern in description\n",
    "class TranslateWithExamples(dspy.Signature):\n",
    "    \"\"\"Translate English text to French.\n",
    "    \n",
    "    Examples:\n",
    "    - Hello -> Bonjour\n",
    "    - Good morning -> Bonjour  \n",
    "    - How are you? -> Comment allez-vous?\n",
    "    - Thank you -> Merci\n",
    "    \"\"\"\n",
    "    english: str = dspy.InputField()\n",
    "    french: str = dspy.OutputField()\n",
    "\n",
    "few_shot_translator = dspy.Predict(TranslateWithExamples)\n",
    "\n",
    "# Test with a new phrase\n",
    "test_phrase = \"Good evening\"\n",
    "print(\"=== Zero-Shot Translation ===\")\n",
    "zero_result = zero_shot_translator(english=test_phrase)\n",
    "print(f\"English: {test_phrase}\")\n",
    "print(f\"French: {zero_result.french}\\n\")\n",
    "\n",
    "print(\"=== Few-Shot Translation (with examples in signature) ===\")\n",
    "few_result = few_shot_translator(english=test_phrase)\n",
    "print(f\"English: {test_phrase}\")\n",
    "print(f\"French: {few_result.french}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0cdb9",
   "metadata": {},
   "source": [
    "### Note on Few-Shot Learning in DSPy\n",
    "\n",
    "**Important**: In DSPy, few-shot learning can be done in several ways:\n",
    "1. **Signature-based** (shown here): Include examples in the signature docstring\n",
    "2. **Teleprompter system**: Use `dspy.LabeledFewShot` or other teleprompters for automatic optimization\n",
    "3. **Manual prompt engineering**: Include examples directly in prompts\n",
    "\n",
    "For production use and automatic optimization, DSPy's teleprompter system (like `LabeledFewShot`, `BootstrapFewShot`) is recommended. The signature-based approach shown here demonstrates the concept clearly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e98a9f",
   "metadata": {},
   "source": [
    "### Few-Shot: Classification with Examples\n",
    "\n",
    "Let's see how few-shot learning improves classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83fda4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Classification Results:\n",
      "============================================================\n",
      "Title: Machine Learning Advances in Healthcare\n",
      "Topic: technology\n",
      "\n",
      "Title: Championship Game Results\n",
      "Topic: sports\n",
      "\n",
      "Title: Breakthrough in Quantum Computing\n",
      "Topic: technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TopicClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the topic of the given article title.\"\"\"\n",
    "    \n",
    "    title: str = dspy.InputField()\n",
    "    topic: Literal[\"technology\", \"sports\", \"science\", \"politics\", \"entertainment\"] = dspy.OutputField()\n",
    "\n",
    "# Create classification examples for reference\n",
    "# These examples demonstrate the pattern we want the model to follow\n",
    "classification_examples = [\n",
    "    dspy.Example(title=\"New AI Model Breaks Records\", topic=\"technology\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"World Cup Finals This Weekend\", topic=\"sports\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Discovery of New Planet\", topic=\"science\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Election Results Announced\", topic=\"politics\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Oscar Nominations Revealed\", topic=\"entertainment\").with_inputs(\"title\"),\n",
    "]\n",
    "\n",
    "# Enhanced signature with few-shot examples in the docstring\n",
    "class TopicClassifierFewShot(dspy.Signature):\n",
    "    \"\"\"Classify the topic of the given article title.\n",
    "    \n",
    "    Examples:\n",
    "    - \"New AI Model Breaks Records\" -> technology\n",
    "    - \"World Cup Finals This Weekend\" -> sports\n",
    "    - \"Discovery of New Planet\" -> science\n",
    "    - \"Election Results Announced\" -> politics\n",
    "    - \"Oscar Nominations Revealed\" -> entertainment\n",
    "    \"\"\"\n",
    "    title: str = dspy.InputField()\n",
    "    topic: Literal[\"technology\", \"sports\", \"science\", \"politics\", \"entertainment\"] = dspy.OutputField()\n",
    "\n",
    "# Create classifiers\n",
    "zero_shot_classifier = dspy.Predict(TopicClassifier)\n",
    "few_shot_classifier = dspy.Predict(TopicClassifierFewShot)\n",
    "\n",
    "# Test classification on new titles\n",
    "test_titles = [\n",
    "    \"Machine Learning Advances in Healthcare\",\n",
    "    \"Championship Game Results\",\n",
    "    \"Breakthrough in Quantum Computing\"\n",
    "]\n",
    "\n",
    "print(\"Few-Shot Classification Results:\")\n",
    "print(\"=\"*60)\n",
    "for title in test_titles:\n",
    "    few_result = few_shot_classifier(title=title)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Topic: {few_result.topic}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f6384",
   "metadata": {},
   "source": [
    "### Comparing Zero-Shot vs Few-Shot\n",
    "\n",
    "Let's compare the same task with and without examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf5907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-Shot Formatting ===\n",
      "Input: 2024-03-20\n",
      "Output: March 20, 2024\n",
      "\n",
      "=== Few-Shot Formatting ===\n",
      "Input: 2024-03-20\n",
      "Output: March 20, 2024\n"
     ]
    }
   ],
   "source": [
    "class FormatDate(dspy.Signature):\n",
    "    \"\"\"Format the date in a readable format.\"\"\"\n",
    "    \n",
    "    date_input: str = dspy.InputField()\n",
    "    formatted_date: str = dspy.OutputField()\n",
    "\n",
    "# Enhanced signature with few-shot examples\n",
    "class FormatDateFewShot(dspy.Signature):\n",
    "    \"\"\"Format the date in a readable format.\n",
    "    \n",
    "    Examples:\n",
    "    - \"2024-01-15\" -> \"January 15, 2024\"\n",
    "    - \"2023-12-25\" -> \"December 25, 2023\"\n",
    "    - \"2024-07-04\" -> \"July 4, 2024\"\n",
    "    \"\"\"\n",
    "    date_input: str = dspy.InputField()\n",
    "    formatted_date: str = dspy.OutputField()\n",
    "\n",
    "# Zero-shot (no examples)\n",
    "zero_shot_formatter = dspy.Predict(FormatDate)\n",
    "\n",
    "# Few-shot (with examples in signature)\n",
    "few_shot_formatter = dspy.Predict(FormatDateFewShot)\n",
    "\n",
    "test_date = \"2024-03-20\"\n",
    "\n",
    "print(\"=== Zero-Shot Formatting ===\")\n",
    "zero_result = zero_shot_formatter(date_input=test_date)\n",
    "print(f\"Input: {test_date}\")\n",
    "print(f\"Output: {zero_result.formatted_date}\\n\")\n",
    "\n",
    "print(\"=== Few-Shot Formatting ===\")\n",
    "few_result = few_shot_formatter(date_input=test_date)\n",
    "print(f\"Input: {test_date}\")\n",
    "print(f\"Output: {few_result.formatted_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb2199",
   "metadata": {},
   "source": [
    "## 5. Chain of Thought (CoT) Reasoning\n",
    "\n",
    "**Chain of Thought** breaks down complex problems into reasoning steps. DSPy's `ChainOfThought` module automatically structures this.\n",
    "\n",
    "### Basic Chain of Thought Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b9f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Two dice are tossed. What is the probability that the sum equals two?\n",
      "\n",
      "Reasoning: When two dice are tossed, there are 6 possible outcomes for the first die and 6 possible outcomes for the second die. The total number of possible outcomes is 6 * 6 = 36.\n",
      "\n",
      "We want to find the number of outcomes where the sum of the two dice equals two.\n",
      "The minimum value a single die can show is 1.\n",
      "Therefore, the only way to get a sum of two is if both dice show a 1.\n",
      "This corresponds to the outcome (1, 1).\n",
      "\n",
      "There is only 1 favorable outcome.\n",
      "\n",
      "The probability is calculated as:\n",
      "P(sum = 2) = (Number of favorable outcomes) / (Total number of possible outcomes)\n",
      "P(sum = 2) = 1 / 36\n",
      "\n",
      "To express this as a float: 1 / 36 = 0.027777777777777776\n",
      "Rounding to a reasonable number of decimal places or using the exact fraction if not explicitly asked for a specific precision. As it asks for a float, I'll provide the exact division.\n",
      "Answer: 0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "# ChainOfThought automatically adds reasoning steps\n",
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "\n",
    "result = math(question=\"Two dice are tossed. What is the probability that the sum equals two?\")\n",
    "print(f\"Question: Two dice are tossed. What is the probability that the sum equals two?\")\n",
    "print(f\"\\nReasoning: {result.reasoning}\")\n",
    "print(f\"Answer: {result.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06840def",
   "metadata": {},
   "source": [
    "### Chain of Thought with Custom Signature\n",
    "\n",
    "For more control, define a custom signature with explicit reasoning field:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7039abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: If a train travels 120 km in 2 hours, what is its average speed?\n",
      "\n",
      "Reasoning:\n",
      "The problem asks for the average speed of a train.\n",
      "The formula for average speed is:\n",
      "Average Speed = Total Distance / Total Time\n",
      "\n",
      "Given:\n",
      "Total Distance = 120 km\n",
      "Total Time = 2 hours\n",
      "\n",
      "Substitute the given values into the formula:\n",
      "Average Speed = 120 km / 2 hours\n",
      "Average Speed = 60 km/h\n",
      "\n",
      "Therefore, the average speed of the train is 60 km/h.\n",
      "\n",
      "Answer: 60.0 km/h\n"
     ]
    }
   ],
   "source": [
    "class SolveProblem(dspy.Signature):\n",
    "    \"\"\"Solve the given math problem step by step.\"\"\"\n",
    "    \n",
    "    problem: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField(desc=\"Show your step-by-step reasoning\")\n",
    "    answer: float = dspy.OutputField()\n",
    "\n",
    "# Use ChainOfThought with custom signature\n",
    "math_solver = dspy.ChainOfThought(SolveProblem)\n",
    "\n",
    "result = math_solver(problem=\"If a train travels 120 km in 2 hours, what is its average speed?\")\n",
    "print(f\"Problem: If a train travels 120 km in 2 hours, what is its average speed?\")\n",
    "print(f\"\\nReasoning:\\n{result.reasoning}\")\n",
    "print(f\"\\nAnswer: {result.answer} km/h\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dac5c6",
   "metadata": {},
   "source": [
    "### Chain of Thought: Logic Problems\n",
    "\n",
    "CoT is especially useful for logical reasoning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83b563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle:\n",
      "\n",
      "Three friends are sitting in a row: Alice, Bob, and Charlie.\n",
      "Alice is sitting to the left of Bob.\n",
      "Charlie is sitting to the left of Alice.\n",
      "Who is sitting in the middle?\n",
      "\n",
      "\n",
      "Reasoning:\n",
      "Let's denote the positions from left to right.\n",
      "1. \"Alice is sitting to the left of Bob.\"\n",
      "   This implies the partial order: A, B\n",
      "\n",
      "2. \"Charlie is sitting to the left of Alice.\"\n",
      "   This implies the partial order: C, A\n",
      "\n",
      "Now, we combine these two pieces of information:\n",
      "From (2), we have C, A.\n",
      "From (1), we know that B is to the right of A.\n",
      "So, extending C, A to include B, we get C, A, B.\n",
      "\n",
      "The full order from left to right is Charlie, Alice, Bob.\n",
      "In this sequence, Alice is in the middle.\n",
      "\n",
      "Answer: Alice\n"
     ]
    }
   ],
   "source": [
    "class LogicPuzzle(dspy.Signature):\n",
    "    \"\"\"Solve the logic puzzle step by step.\"\"\"\n",
    "    \n",
    "    puzzle: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "logic_solver = dspy.ChainOfThought(LogicPuzzle)\n",
    "\n",
    "puzzle = \"\"\"\n",
    "Three friends are sitting in a row: Alice, Bob, and Charlie.\n",
    "Alice is sitting to the left of Bob.\n",
    "Charlie is sitting to the left of Alice.\n",
    "Who is sitting in the middle?\n",
    "\"\"\"\n",
    "\n",
    "result = logic_solver(puzzle=puzzle)\n",
    "print(\"Puzzle:\")\n",
    "print(puzzle)\n",
    "print(f\"\\nReasoning:\\n{result.reasoning}\")\n",
    "print(f\"\\nAnswer: {result.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1459ec",
   "metadata": {},
   "source": [
    "## 6. Combining Techniques: Few-Shot + Chain of Thought\n",
    "\n",
    "You can combine few-shot examples with chain of thought reasoning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb351783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Problem: Tom has 12 stickers. He buys 5 more, then uses 3. How many stickers does he have now?\n",
      "\n",
      "============================================================\n",
      "Reasoning:\n",
      "Tom starts with 12 stickers. He buys 5 more, so he has 12 + 5 = 17 stickers. Then he uses 3 stickers, so he has 17 - 3 = 14 stickers left.\n",
      "\n",
      "============================================================\n",
      "Answer: 14.0\n"
     ]
    }
   ],
   "source": [
    "class WordProblem(dspy.Signature):\n",
    "    \"\"\"Solve the word problem showing your work.\n",
    "    \n",
    "    Examples with reasoning:\n",
    "    - Problem: \"Sarah has 5 apples. She gives 2 to her friend. How many does she have left?\"\n",
    "      Reasoning: \"Sarah starts with 5 apples. After giving 2 away: 5 - 2 = 3\"\n",
    "      Answer: 3.0\n",
    "    \n",
    "    - Problem: \"A pizza has 8 slices. If 3 people each eat 2 slices, how many slices are left?\"\n",
    "      Reasoning: \"Total slices eaten: 3 people Ã— 2 slices = 6 slices. Remaining: 8 - 6 = 2\"\n",
    "      Answer: 2.0\n",
    "    \"\"\"\n",
    "    problem: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField()\n",
    "    answer: float = dspy.OutputField()\n",
    "\n",
    "# Combine ChainOfThought with few-shot examples (in signature)\n",
    "# This gives us both example-based learning AND step-by-step reasoning\n",
    "combined_solver = dspy.ChainOfThought(WordProblem)\n",
    "\n",
    "test_problem = \"Tom has 12 stickers. He buys 5 more, then uses 3. How many stickers does he have now?\"\n",
    "result = combined_solver(problem=test_problem)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Problem: {test_problem}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Reasoning:\\n{result.reasoning}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Answer: {result.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689c92a",
   "metadata": {},
   "source": [
    "### How DSPy Enhances Prompts\n",
    "\n",
    "DSPy automatically enhances prompts in several ways:\n",
    "\n",
    "1. **Structured Formatting**: Converts signatures into well-formatted prompts\n",
    "2. **Type Safety**: Ensures outputs match expected types\n",
    "3. **Documentation**: Uses docstrings and field descriptions in prompts\n",
    "4. **Example Selection**: Intelligently selects relevant examples for few-shot\n",
    "5. **Reasoning Chains**: Automatically structures reasoning steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9a490",
   "metadata": {},
   "source": [
    "## 8. Advanced Example: Multi-Step Reasoning\n",
    "\n",
    "Let's create a more complex example combining multiple techniques:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01fe63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "\n",
      "Artificial intelligence is transforming healthcare in remarkable ways. \n",
      "Machine learning algorithms can now detect diseases earlier than ever before, \n",
      "leading to better patient outcomes. However, there are concerns about data \n",
      "privacy and the need for human oversight in critical medical decisions.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Reasoning:\n",
      "The text highlights the positive impact of AI and machine learning in healthcare, specifically mentioning earlier disease detection and better patient outcomes. However, it also raises concerns about data privacy and the necessity of human oversight. The overall tone is cautiously optimistic, focusing on the benefits while acknowledging critical challenges. Therefore, the sentiment is primarily positive due to the stated benefits, with important caveats. Topics clearly include artificial intelligence, healthcare, disease detection, data privacy, and human oversight.\n",
      "\n",
      "============================================================\n",
      "Sentiment: positive\n",
      "Topics: Artificial intelligence, Healthcare, Machine learning, Disease detection, Patient outcomes, Data privacy, Human oversight\n",
      "Summary: Artificial intelligence and machine learning are revolutionizing healthcare through earlier disease detection and improved patient outcomes. However, this progress is accompanied by significant concerns regarding data privacy and the ongoing need for human oversight in medical decisions.\n"
     ]
    }
   ],
   "source": [
    "class AnalyzeText(dspy.Signature):\n",
    "    \"\"\"Analyze the given text for sentiment, extract key topics, and summarize.\"\"\"\n",
    "    \n",
    "    text: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField(desc=\"Think step by step about sentiment and topics\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = dspy.OutputField()\n",
    "    topics: str = dspy.OutputField(desc=\"Comma-separated list of main topics\")\n",
    "    summary: str = dspy.OutputField(desc=\"Brief summary in 1-2 sentences\")\n",
    "\n",
    "# Use ChainOfThought for multi-aspect analysis\n",
    "analyzer = dspy.ChainOfThought(AnalyzeText)\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Artificial intelligence is transforming healthcare in remarkable ways. \n",
    "Machine learning algorithms can now detect diseases earlier than ever before, \n",
    "leading to better patient outcomes. However, there are concerns about data \n",
    "privacy and the need for human oversight in critical medical decisions.\n",
    "\"\"\"\n",
    "\n",
    "result = analyzer(text=sample_text)\n",
    "\n",
    "print(\"Input Text:\")\n",
    "print(sample_text)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Reasoning:\\n{result.reasoning}\\n\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(f\"Topics: {result.topics}\")\n",
    "print(f\"Summary: {result.summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90fbf4",
   "metadata": {},
   "source": [
    "## 9. Using DSPy Evaluators to Measure Performance\n",
    "\n",
    "You can use DSPy's built-in evaluators to measure the accuracy or quality of your modules. Below is an example that evaluates a few-shot classifier using the `Accuracy` evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982775b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/22 15:56:55 INFO dspy.evaluate.evaluate: Average Metric: 4 / 5 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.0\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluating a Few-Shot Classifier with DSPy Evaluators\n",
    "import dspy\n",
    "from typing import Literal\n",
    "\n",
    "# Define a signature for topic classification\n",
    "class TopicClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the topic of the given article title.\"\"\"\n",
    "    title: str = dspy.InputField()\n",
    "    topic: Literal[\"technology\", \"sports\", \"science\", \"politics\", \"entertainment\"] = dspy.OutputField()\n",
    "\n",
    "# Few-shot examples\n",
    "examples = [\n",
    "    dspy.Example(title=\"New AI Model Breaks Records\", topic=\"technology\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"World Cup Finals This Weekend\", topic=\"sports\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Discovery of New Planet\", topic=\"science\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Election Results Announced\", topic=\"politics\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Oscar Nominations Revealed\", topic=\"entertainment\").with_inputs(\"title\"),\n",
    "]\n",
    "\n",
    "# Create a few-shot classifier using the examples\n",
    "classifier = dspy.Predict(TopicClassifier, examples=examples)\n",
    "\n",
    "# Evaluation set\n",
    "eval_set = [\n",
    "    dspy.Example(title=\"Breakthrough in Quantum Computing\", topic=\"technology\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"World Cup Qualifiers Announced\", topic=\"sports\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Mars Rover Sends New Photos\", topic=\"science\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Senate Passes New Bill\", topic=\"politics\").with_inputs(\"title\"),\n",
    "    dspy.Example(title=\"Film Festival Winners Announced\", topic=\"entertainment\").with_inputs(\"title\"),\n",
    "]\n",
    "\n",
    "# Use DSPy's built-in Accuracy evaluator\n",
    "def accuracy_metric(example, pred, trace=None):\n",
    "    return example.topic == pred.topic  # Adjust field names as needed\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=eval_set, metric=accuracy_metric)\n",
    "results = evaluate(classifier)\n",
    "print(f\"Accuracy: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43786622",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Zero-Shot (`dspy.Predict`)**: Direct predictions using signatures\n",
    "   - Use for tasks where the model has inherent understanding\n",
    "   - Simple and fast\n",
    "   - Best for straightforward tasks\n",
    "\n",
    "2. **Few-Shot (Examples in Signatures)**: Learning from examples\n",
    "   - Provides context through examples in signature docstrings\n",
    "   - Improves performance on specific patterns\n",
    "   - Best when you have good examples\n",
    "   - Can also use DSPy's teleprompter for automatic few-shot optimization\n",
    "\n",
    "3. **Chain of Thought (`dspy.ChainOfThought`)**: Step-by-step reasoning\n",
    "   - Breaks down complex problems\n",
    "   - Shows reasoning process\n",
    "   - Best for math, logic, and complex reasoning tasks\n",
    "\n",
    "4. **Custom Signatures**: Structured input/output definitions\n",
    "   - Type safety and validation\n",
    "   - Clear documentation\n",
    "   - Reusable components\n",
    "\n",
    "5. **DSPy Evaluators**:DSPy's built-in evaluators to measure the accuracy or quality of your modules.  \n",
    "   -Enhances accuracy  \n",
    "   -Evaluates Performance Of the modules    \n",
    "\n",
    "### How DSPy Enhances Prompts\n",
    "\n",
    "- âœ… **Automatic formatting** from Python code\n",
    "- âœ… **Type validation** ensures correct outputs\n",
    "- âœ… **Smart example selection** for few-shot\n",
    "- âœ… **Reasoning chain structure** for CoT\n",
    "- âœ… **Composable modules** for complex pipelines\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore **optimization** with `dspy.teleprompter`\n",
    "- Learn about **retrieval** and **RAG** integration\n",
    "- Build **pipelines** combining multiple modules\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
